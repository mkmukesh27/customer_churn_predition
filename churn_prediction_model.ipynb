{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_No</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>...</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>tenure_group_1 - 12</th>\n",
       "      <th>tenure_group_13 - 24</th>\n",
       "      <th>tenure_group_25 - 36</th>\n",
       "      <th>tenure_group_37 - 48</th>\n",
       "      <th>tenure_group_49 - 60</th>\n",
       "      <th>tenure_group_61 - 72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SeniorCitizen  MonthlyCharges  TotalCharges  Churn  \\\n",
       "0           0              0           29.85         29.85      0   \n",
       "1           1              0           56.95       1889.50      0   \n",
       "2           2              0           53.85        108.15      1   \n",
       "3           3              0           42.30       1840.75      0   \n",
       "4           4              0           70.70        151.65      1   \n",
       "\n",
       "   gender_Female  gender_Male  Partner_No  Partner_Yes  Dependents_No  ...  \\\n",
       "0              1            0           0            1              1  ...   \n",
       "1              0            1           1            0              1  ...   \n",
       "2              0            1           1            0              1  ...   \n",
       "3              0            1           1            0              1  ...   \n",
       "4              1            0           1            0              1  ...   \n",
       "\n",
       "   PaymentMethod_Bank transfer (automatic)  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PaymentMethod_Mailed check  tenure_group_1 - 12  tenure_group_13 - 24  \\\n",
       "0                           0                    1                     0   \n",
       "1                           1                    0                     0   \n",
       "2                           1                    1                     0   \n",
       "3                           0                    0                     0   \n",
       "4                           0                    1                     0   \n",
       "\n",
       "   tenure_group_25 - 36  tenure_group_37 - 48  tenure_group_49 - 60  \\\n",
       "0                     0                     0                     0   \n",
       "1                     1                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     1                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   tenure_group_61 - 72  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"tel_churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_No</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>tenure_group_1 - 12</th>\n",
       "      <th>tenure_group_13 - 24</th>\n",
       "      <th>tenure_group_25 - 36</th>\n",
       "      <th>tenure_group_37 - 48</th>\n",
       "      <th>tenure_group_49 - 60</th>\n",
       "      <th>tenure_group_61 - 72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  MonthlyCharges  TotalCharges  Churn  gender_Female  \\\n",
       "0              0           29.85         29.85      0              1   \n",
       "1              0           56.95       1889.50      0              0   \n",
       "2              0           53.85        108.15      1              0   \n",
       "3              0           42.30       1840.75      0              0   \n",
       "4              0           70.70        151.65      1              1   \n",
       "\n",
       "   gender_Male  Partner_No  Partner_Yes  Dependents_No  Dependents_Yes  ...  \\\n",
       "0            0           0            1              1               0  ...   \n",
       "1            1           1            0              1               0  ...   \n",
       "2            1           1            0              1               0  ...   \n",
       "3            1           1            0              1               0  ...   \n",
       "4            0           1            0              1               0  ...   \n",
       "\n",
       "   PaymentMethod_Bank transfer (automatic)  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PaymentMethod_Mailed check  tenure_group_1 - 12  tenure_group_13 - 24  \\\n",
       "0                           0                    1                     0   \n",
       "1                           1                    0                     0   \n",
       "2                           1                    1                     0   \n",
       "3                           0                    0                     0   \n",
       "4                           0                    1                     0   \n",
       "\n",
       "   tenure_group_25 - 36  tenure_group_37 - 48  tenure_group_49 - 60  \\\n",
       "0                     0                     0                     0   \n",
       "1                     1                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     1                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   tenure_group_61 - 72  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_No</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_No</th>\n",
       "      <th>...</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>tenure_group_1 - 12</th>\n",
       "      <th>tenure_group_13 - 24</th>\n",
       "      <th>tenure_group_25 - 36</th>\n",
       "      <th>tenure_group_37 - 48</th>\n",
       "      <th>tenure_group_49 - 60</th>\n",
       "      <th>tenure_group_61 - 72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7027</td>\n",
       "      <td>0</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>0</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>0</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>1</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>0</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SeniorCitizen  MonthlyCharges  TotalCharges  gender_Female  gender_Male  \\\n",
       "0                 0           29.85         29.85              1            0   \n",
       "1                 0           56.95       1889.50              0            1   \n",
       "2                 0           53.85        108.15              0            1   \n",
       "3                 0           42.30       1840.75              0            1   \n",
       "4                 0           70.70        151.65              1            0   \n",
       "...             ...             ...           ...            ...          ...   \n",
       "7027              0           84.80       1990.50              0            1   \n",
       "7028              0          103.20       7362.90              1            0   \n",
       "7029              0           29.60        346.45              1            0   \n",
       "7030              1           74.40        306.60              0            1   \n",
       "7031              0          105.65       6844.50              0            1   \n",
       "\n",
       "      Partner_No  Partner_Yes  Dependents_No  Dependents_Yes  PhoneService_No  \\\n",
       "0              0            1              1               0                1   \n",
       "1              1            0              1               0                0   \n",
       "2              1            0              1               0                0   \n",
       "3              1            0              1               0                1   \n",
       "4              1            0              1               0                0   \n",
       "...          ...          ...            ...             ...              ...   \n",
       "7027           0            1              0               1                0   \n",
       "7028           0            1              0               1                0   \n",
       "7029           0            1              0               1                1   \n",
       "7030           0            1              1               0                0   \n",
       "7031           1            0              1               0                0   \n",
       "\n",
       "      ...  PaymentMethod_Bank transfer (automatic)  \\\n",
       "0     ...                                        0   \n",
       "1     ...                                        0   \n",
       "2     ...                                        0   \n",
       "3     ...                                        1   \n",
       "4     ...                                        0   \n",
       "...   ...                                      ...   \n",
       "7027  ...                                        0   \n",
       "7028  ...                                        0   \n",
       "7029  ...                                        0   \n",
       "7030  ...                                        0   \n",
       "7031  ...                                        1   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                         0                               1   \n",
       "1                                         0                               0   \n",
       "2                                         0                               0   \n",
       "3                                         0                               0   \n",
       "4                                         0                               1   \n",
       "...                                     ...                             ...   \n",
       "7027                                      0                               0   \n",
       "7028                                      1                               0   \n",
       "7029                                      0                               1   \n",
       "7030                                      0                               0   \n",
       "7031                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  tenure_group_1 - 12  tenure_group_13 - 24  \\\n",
       "0                              0                    1                     0   \n",
       "1                              1                    0                     0   \n",
       "2                              1                    1                     0   \n",
       "3                              0                    0                     0   \n",
       "4                              0                    1                     0   \n",
       "...                          ...                  ...                   ...   \n",
       "7027                           1                    0                     1   \n",
       "7028                           0                    0                     0   \n",
       "7029                           0                    1                     0   \n",
       "7030                           1                    1                     0   \n",
       "7031                           0                    0                     0   \n",
       "\n",
       "      tenure_group_25 - 36  tenure_group_37 - 48  tenure_group_49 - 60  \\\n",
       "0                        0                     0                     0   \n",
       "1                        1                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     1                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "7027                     0                     0                     0   \n",
       "7028                     0                     0                     0   \n",
       "7029                     0                     0                     0   \n",
       "7030                     0                     0                     0   \n",
       "7031                     0                     0                     0   \n",
       "\n",
       "      tenure_group_61 - 72  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "7027                     0  \n",
       "7028                     1  \n",
       "7029                     0  \n",
       "7030                     0  \n",
       "7031                     1  \n",
       "\n",
       "[7032 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.drop('Churn',axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "7027    0\n",
       "7028    0\n",
       "7029    0\n",
       "7030    1\n",
       "7031    0\n",
       "Name: Churn, Length: 7032, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['Churn']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model=ExtraTreesRegressor()\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.75114799e-02 1.05208521e-01 1.46816110e-01 2.19547235e-02\n",
      " 2.12647881e-02 1.96824657e-02 1.94433415e-02 1.62776520e-02\n",
      " 1.65171920e-02 2.39632053e-03 2.61160470e-03 1.47026246e-02\n",
      " 2.30007002e-03 1.31618497e-02 8.26730343e-05 5.42922406e-02\n",
      " 6.74159443e-05 1.97489459e-02 1.22385279e-04 1.06369209e-02\n",
      " 1.70062253e-02 2.23486489e-04 1.59535197e-02 1.52734984e-02\n",
      " 2.22023284e-04 1.56980316e-02 1.27461812e-02 3.27417200e-04\n",
      " 1.27164701e-02 1.13176787e-02 7.42293480e-05 1.09083925e-02\n",
      " 1.15304268e-02 8.93501708e-05 1.27485251e-02 1.64863878e-01\n",
      " 1.75056729e-03 1.90380774e-03 1.73035753e-02 1.72311758e-02\n",
      " 1.64903880e-02 1.52802877e-02 2.31109334e-02 1.51740933e-02\n",
      " 3.82708008e-02 8.21389057e-03 8.21803170e-03 8.49030279e-03\n",
      " 8.21700457e-03 3.84648247e-03]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5625, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model_dt.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traninig Accuracy is :  99.78666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"traninig Accuracy is : \", model_dt.score(x_train,y_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy is :  71.78393745557925\n"
     ]
    }
   ],
   "source": [
    "print(\"testing Accuracy is : \", model_dt.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7178393745557925"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1035\n",
      "           1       0.47      0.49      0.48       372\n",
      "\n",
      "    accuracy                           0.72      1407\n",
      "   macro avg       0.64      0.65      0.64      1407\n",
      "weighted avg       0.72      0.72      0.72      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[827 208]\n",
      " [189 183]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As you can see that the accuracy is quite low, and as it's an imbalanced dataset, we shouldn't consider Accuracy as our metrics to measure the model, as Accuracy is cursed in imbalanced datasets.\n",
    "\n",
    "###### Hence, we need to check recall, precision & f1 score for the minority class, and it's quite evident that the precision, recall & f1 score is too low for Class 1, i.e. churned customers.\n",
    "\n",
    "###### Hence, moving ahead to call SMOTEENN (UpSampling + ENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTEENN()\n",
    "x_resampled, y_resampled = sm.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_train,xr_test,yr_train,yr_test=train_test_split(x_resampled,y_resampled,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_smote=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt_smote.fit(xr_train,yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_smote=model_dt_smote.predict(xr_test)\n",
    "y_pred_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traninig Accuracy is :  100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"traninig Accuracy is : \", model_dt_smote.score(xr_train,yr_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy is :  94.39252336448598\n"
     ]
    }
   ],
   "source": [
    "print(\"testing Accuracy is : \", model_dt_smote.score(xr_test,yr_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439252336448598"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt_smote.score(xr_test,yr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       524\n",
      "           1       0.95      0.95      0.95       653\n",
      "\n",
      "    accuracy                           0.94      1177\n",
      "   macro avg       0.94      0.94      0.94      1177\n",
      "weighted avg       0.94      0.94      0.94      1177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yr_test, y_pred_smote, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[490  34]\n",
      " [ 32 621]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yr_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we can see quite better results, i.e. Accuracy: 92 %, and a very good recall, precision & f1 score for minority class.\n",
    "\n",
    "###### Let's try with some other classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_pred=rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7718550106609808"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranini Accuracy is :  99.78666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"tranini Accuracy is : \", rf_model.score(x_train,y_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy is :  77.18550106609808\n"
     ]
    }
   ],
   "source": [
    "print(\"testing Accuracy is : \", rf_model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      1035\n",
      "           1       0.59      0.45      0.51       372\n",
      "\n",
      "    accuracy                           0.77      1407\n",
      "   macro avg       0.70      0.67      0.68      1407\n",
      "weighted avg       0.76      0.77      0.76      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yr_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTEENN()\n",
    "X_resampled1, y_resampled1 = sm.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_train1,xr_test1,yr_train1,yr_test1=train_test_split(X_resampled1, y_resampled1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_smote=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_smote=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_smote.fit(xr_train1,yr_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_predict1 = rf_model_smote.predict(xr_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_r1 = rf_model_smote.score(xr_test1, yr_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9516129032258065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       545\n",
      "           1       0.95      0.96      0.96       633\n",
      "\n",
      "    accuracy                           0.95      1178\n",
      "   macro avg       0.95      0.95      0.95      1178\n",
      "weighted avg       0.95      0.95      0.95      1178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_score_r1)\n",
    "print(metrics.classification_report(yr_test1, yr_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy is :  95.16129032258065\n"
     ]
    }
   ],
   "source": [
    "print(\"testing Accuracy is : \", rf_model_smote.score(xr_test1,yr_test1)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516129032258065"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_smote.score(xr_test1,yr_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[511  34]\n",
      " [ 23 610]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yr_test1, yr_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model=XGBClassifier(objective='binary:logistic')\n",
    "xg_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traninig Accuracy is :  92.99555555555555\n"
     ]
    }
   ],
   "source": [
    "print(\"traninig Accuracy is : \", xg_model.score(x_train,y_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy is :  78.67803837953092\n"
     ]
    }
   ],
   "source": [
    "print(\"testing Accuracy is : \", xg_model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1035\n",
      "           1       0.47      0.49      0.48       372\n",
      "\n",
      "    accuracy                           0.72      1407\n",
      "   macro avg       0.64      0.65      0.64      1407\n",
      "weighted avg       0.72      0.72      0.72      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "#### Choose Following method\n",
    "1. RandomizedSearchCV -->fast\n",
    "2. GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'learning_rate':[1,0.5,0.1,0.01],\n",
    "    'max_depth':[3,5,10,20],\n",
    "    'n_estimators':[10,50,100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=RandomizedSearchCV(XGBClassifier(objective='binari:logistic'), param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:13] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.5, max_depth=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.5, max_depth=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\", line 1187, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 197, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 1501, in update\n",
      "    dtrain.handle))\n",
      "  File \"E:\\Python\\lib\\site-packages\\xgboost\\core.py\", line 210, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n",
      "E:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: reg:pseudohubererror\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-807fe847b3e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m         )\n\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    195\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [00:02:14] C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.4.0\\src\\objective\\objective.cc:26: Unknown objective function: `binari:logistic`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: reg:pseudohubererror\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\n"
     ]
    }
   ],
   "source": [
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=1, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model=XGBClassifier(n_estimators = 50, max_depth = 10, learning_rate = 1)\n",
    "xg_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Accuracy is :  99.76888888888888\n"
     ]
    }
   ],
   "source": [
    "print(\"training Accuracy is : \", xg_model.score(x_train,y_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy is :  76.47476901208245\n"
     ]
    }
   ],
   "source": [
    "print(\"testing Accuracy is : \", xg_model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.pkl'\n",
    "pickle.dump(rf_model_smote, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516129032258065"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.score(xr_test1,yr_test1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
